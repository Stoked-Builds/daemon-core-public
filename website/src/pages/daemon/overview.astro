---
import BaseLayout from '../../layouts/BaseLayout.astro';
---

<BaseLayout title="Overview (Legacy) - DaemonCore" description="Original overview document. See updated pages for current framing.">
  <article class="article">
    <h1>Overview</h1>

    <div class="legacy-banner">
      <strong>Legacy Document</strong>
      <p>
        This is an earlier overview. For current framing, see:
        <a href="/daemon/what-it-is">What It Is</a>,
        <a href="/daemon/walkthrough">Walkthrough</a>, or
        <a href="/daemon/why-different">Why Different</a>.
      </p>
    </div>

    <p>
      DaemonCore is a <strong>governance layer</strong>: the structural foundation
      beneath orchestration that defines what agents are allowed to do. It provides
      protocol validation, boundary enforcement, and deterministic behaviour.
    </p>

    <p>
      The purpose is not coordination—that's what orchestrators do. The purpose is
      governance: ensuring agents operate within defined constraints they cannot override.
    </p>

    <h2>Problem Statement</h2>
    <p>
      Current AI systems lack architectural discipline. Daemon Core addresses this
      through structural constraints, not prompt engineering.
      <a href="/daemon/why-different">See the full rationale.</a>
    </p>

    <h2>Solution Architecture</h2>
    <p>
      Agents under Daemon Core do not receive isolated prompts. They boot into
      a structured context stack: global preferences, project state, task scope.
    </p>
    <p>
      The stack is deterministic. Given identical inputs, agent behavior is predictable.
    </p>

    <h3>Core Mechanisms</h3>

    <h4>Boot Sequence</h4>
    <p>
      Agents follow a defined initialisation protocol. Context loads in layers.
      State is explicit at every step. No implicit assumptions.
    </p>

    <h4>Vendor Isolation</h4>
    <p>
      Each AI provider operates within isolated configuration. No cross-contamination.
      Models can be substituted without restructuring.
    </p>

    <h4>Environment Awareness</h4>
    <p>
      Agents report execution context at boot. Hardware constraints, network access,
      available tooling. Behavior adapts to environment parameters.
    </p>

    <h4>Safety Scaling</h4>
    <p>
      Permissions correlate with environment trust. Constrained environments receive
      restricted capabilities. High-trust deployments may operate with greater autonomy.
    </p>

    <h4>Session Persistence</h4>
    <p>
      Context persists within defined boundaries. Agents resume from established state.
      No repeated context reconstruction.
    </p>

    <h2>Negative Definition</h2>
    <ul>
      <li><strong>Not an AI model</strong> – operates alongside existing models.</li>
      <li><strong>Not an interface</strong> – focuses on behavior, not presentation.</li>
      <li><strong>Not prompt engineering</strong> – defines runtime environment.</li>
      <li><strong>Not vendor-specific</strong> – designed for multi-provider operation.</li>
    </ul>

    <h2>Design Principles</h2>
    <ol>
      <li><strong>Determinism</strong> – identical inputs produce identical behavior.</li>
      <li><strong>Transparency</strong> – agents declare state and capabilities explicitly.</li>
      <li><strong>Constraint-first</strong> – restrictions are default; permissions are earned.</li>
      <li><strong>Composability</strong> – components combine without modification.</li>
      <li><strong>Human authority</strong> – critical decisions require human approval.</li>
    </ol>
  </article>
</BaseLayout>
